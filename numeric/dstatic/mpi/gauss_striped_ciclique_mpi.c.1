/*
	la function pour faire elimation gaussiene dans le reseau ciclique avec
	distribution striped dans MPI clasique
*/
#include<parallel/parallel-mpi.h>
void gauss_striped_ciclique_mpi(int rank,int size,int partition,int *ciclique,int derniere,double **augumente,double *resoudre,int variable)
/*
	rank c'est le numero de processeur
	size c'est le numero des processeurs
	partition c'est le numero de ligne dans cette machine
	ciclique c'est le vector avec les numeros des lignes
	derniere c'est le flag qui sais si cette machine est la derniere machine de calcul
	augumente c'est la matrice augumente
	resoudre c'est le vector de resoudre
*/
{
double *ligne;
int num,ete;
int l;
int i,j,k,m;
int temp[2];
MPI_Status status;
	ligne=(double *)calloc(variable+1,sizeof(double));
	ete=0;
	for(i=0;i<partition;i++)
	{
		for(k=ete;k<ciclique[i];k++)
		{
			l=rank-1;
			if(l<0) l=size-1;
			MPI_Recv(temp,2,MPI_INT,l,0,MPI_COMM_WORLD,&status);
			MPI_Recv(&ligne[temp[0]],(variable-temp[0]+1),MPI_DOUBLE,l,1,MPI_COMM_WORLD,&status);
//			MPI_Recv(ligne,variable+1,MPI_DOUBLE,l,1,MPI_COMM_WORLD,&status);
			l=rank+1;
			if(l==size) l=0;
			if((l!=temp[1])&&(!((temp[0]+1+rank-temp[1])>=variable)))
			{
				MPI_Send(temp,2,MPI_INT,l,0,MPI_COMM_WORLD);
				MPI_Send(&ligne[temp[0]],(variable-temp[0]+1),MPI_DOUBLE,l,1,MPI_COMM_WORLD);
//				MPI_Send(ligne,variable+1,MPI_DOUBLE,l,1,MPI_COMM_WORLD);
			}
			//fait elimination pour les lignes qui sont dans le meme machine
			for(m=i;m<partition;m++)
			{
				for(j=temp[0]+1;j<variable+1;j++)
					augumente[m][j]-=augumente[m][temp[0]]*ligne[j];
				augumente[m][temp[0]]=0.0;
			}
		}
		//faite la division
		for(j=ciclique[i]+1;j<variable+1;j++)
			augumente[i][j]=augumente[i][j]/augumente[i][ciclique[i]];
		augumente[i][ciclique[i]]=1.0;
		resoudre[i]=augumente[i][variable];
		if(!((i==(partition-1))&&(derniere==1)))
		{
			l=rank+1;
			if(l==size) l=0;
			memcpy(ligne,augumente[i],(variable+1)*sizeof(double));
			temp[0]=ciclique[i];
			temp[1]=rank;
			MPI_Send(temp,2,MPI_INT,l,0,MPI_COMM_WORLD);
			MPI_Send(&ligne[temp[0]],(variable-temp[0]+1),MPI_DOUBLE,l,1,MPI_COMM_WORLD);
//			MPI_Send(ligne,(variable+1),MPI_DOUBLE,l,1,MPI_COMM_WORLD);
			//fait elimination pour les lignes qui sont dans le meme machine
			for(k=i+1;k<partition;k++)
			{
				for(j=ciclique[i]+1;j<variable+1;j++)
					augumente[k][j]-=augumente[k][ciclique[i]]*ligne[j];
				augumente[k][ciclique[i]]=0.0;
			}
			ete=ciclique[i]+1;
		}
	}
	MPI_Barrier(MPI_COMM_WORLD);
	if(derniere==1)
		ete=ciclique[partition-1]-1;
	else ete=variable-1;
	for(i=partition-1;i>=0;i--)
	{
		for(k=0;k<(ete-ciclique[i]);k++)
		{
			l=rank+1;
			if(l==size) l=0;
			MPI_Recv(temp,2,MPI_INT,l,0,MPI_COMM_WORLD,&status);
			MPI_Recv(&ligne[0],1,MPI_DOUBLE,l,1,MPI_COMM_WORLD,&status);
			l=rank-1;
			if(l<0) l=size-1;
			if((l!=temp[1])&&!((rank==0)&&(i==0)))
			{
				MPI_Send(temp,2,MPI_INT,l,0,MPI_COMM_WORLD);
				MPI_Send(&ligne[0],1,MPI_DOUBLE,l,1,MPI_COMM_WORLD);
			}
			for(m=0;m<i+1;m++)
				resoudre[m]=resoudre[m]-augumente[m][temp[0]]*ligne[0];
		}
		if(!((i==0)&&(rank==0)))
		{
			l=rank-1;
			if(l<0) l=size-1;
			ligne[0]=resoudre[i];
			temp[0]=ciclique[i];
			temp[1]=rank;
			MPI_Send(temp,2,MPI_INT,l,0,MPI_COMM_WORLD);
			MPI_Send(&ligne[0],1,MPI_DOUBLE,l,1,MPI_COMM_WORLD);
			for(m=0;m<i;m++)
				resoudre[m]=resoudre[m]-augumente[m][temp[0]]*ligne[0];
			ete=ciclique[i]-1;
		}
	}
	MPI_Barrier(MPI_COMM_WORLD);
	free(ligne);
}